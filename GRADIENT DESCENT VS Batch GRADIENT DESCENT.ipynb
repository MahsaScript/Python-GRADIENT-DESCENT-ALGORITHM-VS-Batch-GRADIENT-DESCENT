{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GRADIENT DESCENT ALGORITHM - MultiLayer - Activation Function = Tanh"
      ],
      "metadata": {
        "id": "0y7a1Gq3HE0W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqC2kxe4Wvzn"
      },
      "outputs": [],
      "source": [
        "from random import random\n",
        "from random import seed\n",
        "from ml.activation.Tanh import Tanh\n",
        "\n",
        "class MultilayerNnClassifier:\n",
        "    \n",
        "    def initialize_network_old(self, n_inputs, n_hidden, n_outputs):\n",
        "        '''\n",
        "        Initialize a new neural network ready for training. \n",
        "        It accepts three parameters, the number of inputs, the number of neurons \n",
        "        to have in the hidden layer and the number of outputs.\n",
        "        '''\n",
        "        network = list()\n",
        "        # hidden layer has 'n_hidden' neuron with 'n_inputs' input weights plus the bias\n",
        "        hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "        network.append(hidden_layer)\n",
        "        output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "        network.append(output_layer)\n",
        "        return network\n",
        "    \n",
        "    def initialize_network(self, n_inputs, n_hidden, n_outputs):\n",
        "        '''\n",
        "        Initialize a new neural network ready for training. \n",
        "        It accepts three parameters, the number of inputs, the hidden layers and the number of outputs.\n",
        "        '''\n",
        "        network = list()\n",
        "        h = 0\n",
        "        for hidden in n_hidden:     \n",
        "            if(h==0):       \n",
        "                # hidden layer has 'hidden' neuron with 'n_inputs' input weights plus the bias\n",
        "                hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(hidden)]\n",
        "            else:\n",
        "                # hidden layer has 'hidden' neuron with 'hidden - 1' weights plus the bias\n",
        "                hidden_layer = [{'weights':[random() for i in range(n_hidden[h-1] + 1)]} for i in range(hidden)]\n",
        "            network.append(hidden_layer)\n",
        "            h += 1\n",
        "        # output layer has 'n_outputs' neuron with 'last hidden' weights plus the bias    \n",
        "        output_layer = [{'weights':[random() for i in range(n_hidden[-1] + 1)]} for i in range(n_outputs)]\n",
        "        network.append(output_layer)\n",
        "        return network\n",
        "    \n",
        "    def activate(self, weights, inputs):\n",
        "        '''\n",
        "        Calculate neuron activation for an input is the First step of forward propagation\n",
        "        activation = sum(weight_i * input_i) + bias.\n",
        "        '''\n",
        "        activation = weights[-1]  # Bias\n",
        "        for i in range(len(weights) - 1):\n",
        "            activation += weights[i] * inputs[i]\n",
        "        return activation\n",
        "    \n",
        "    def forward_propagate(self, network, activation_function, row):\n",
        "        '''\n",
        "        Forward propagate input to a network output.\n",
        "        The function returns the outputs from the last layer also called the output layer.\n",
        "        '''\n",
        "        inputs = row\n",
        "        for layer in network:\n",
        "            new_inputs = []\n",
        "            for neuron in layer:\n",
        "                activation = self.activate(neuron['weights'], inputs)\n",
        "                neuron['output'] = activation_function.transfer(activation)\n",
        "                new_inputs.append(neuron['output'])\n",
        "            inputs = new_inputs\n",
        "        return inputs\n",
        "    \n",
        "    def backward_propagate_error(self, network, activation_function, expected):\n",
        "        '''\n",
        "        Backpropagate error and store in neurons.\n",
        "        \n",
        "        The error for a given neuron can be calculated as follows:\n",
        "        \n",
        "            error = (expected - output) * transfer_derivative(output)\n",
        "            \n",
        "        Where expected is the expected output value for the neuron, \n",
        "        output is the output value for the neuron and transfer_derivative() \n",
        "        calculates the slope of the neuron's output value.\n",
        "        \n",
        "        The error signal for a neuron in the hidden layer is calculated as:\n",
        "        \n",
        "            error = (weight_k * error_j) * transfer_derivative(output)\n",
        "            \n",
        "        Where error_j is the error signal from the jth neuron in the output layer, \n",
        "        weight_k is the weight that connects the kth neuron to the current neuron \n",
        "        and output is the output for the current neuron.\n",
        "        '''\n",
        "        for i in reversed(range(len(network))):\n",
        "            layer = network[i]\n",
        "            errors = list()\n",
        "            if i != len(network) - 1:\n",
        "                for j in range(len(layer)):\n",
        "                    error = 0.0\n",
        "                    for neuron in network[i + 1]:\n",
        "                        error += (neuron['weights'][j] * neuron['delta'])\n",
        "                    errors.append(error)\n",
        "            else:\n",
        "                for j in range(len(layer)):\n",
        "                    neuron = layer[j]\n",
        "                    errors.append(expected[j] - neuron['output'])\n",
        "            for j in range(len(layer)):\n",
        "                neuron = layer[j]\n",
        "                neuron['delta'] = errors[j] * activation_function.transfer_derivative(neuron['output'])\n",
        "    \n",
        "    def update_weights(self, network, row, l_rate):\n",
        "        '''\n",
        "        Updates the weights for a network given an input row of data, a learning rate \n",
        "        and assume that a forward and backward propagation have already been performed.\n",
        "        \n",
        "            weight = weight + learning_rate * error * input\n",
        "            \n",
        "        Where weight is a given weight, learning_rate is a parameter that you must specify, \n",
        "        error is the error calculated by the back-propagation procedure for the neuron and \n",
        "        input is the input value that caused the error.\n",
        "        '''\n",
        "        for i in range(len(network)):\n",
        "            inputs = row[:-1]\n",
        "            if i != 0:\n",
        "                inputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "            for neuron in network[i]:\n",
        "                for j in range(len(inputs)):\n",
        "                    neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "                neuron['weights'][-1] += l_rate * neuron['delta']\n",
        "    \n",
        "    def train_network(self, network, activation_function, train, l_rate, n_epoch, n_outputs):\n",
        "        '''\n",
        "        Train a network for a fixed number of epochs.\n",
        "        The network is updated using stochastic gradient descent.\n",
        "        '''\n",
        "        for epoch in range(n_epoch + 1):\n",
        "            sum_error = 0\n",
        "            for row in train:\n",
        "                # Calculate Loss\n",
        "                outputs = self.forward_propagate(network, activation_function, row)\n",
        "                expected = [0 for i in range(n_outputs)]\n",
        "                expected[row[-1]] = 1  # Bias\n",
        "                sum_error += sum([(expected[i] - outputs[i]) ** 2 for i in range(len(expected))])\n",
        "                self.backward_propagate_error(network, activation_function, expected)\n",
        "                self.update_weights(network, row, l_rate)\n",
        "            if (epoch % 100 == 0):    \n",
        "                print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error/float(len(train))))\n",
        "    \n",
        "    def predict(self, network, activationFunction, row):\n",
        "        '''\n",
        "        Make a prediction with a network.\n",
        "        We can use the output values themselves directly as the probability of a pattern belonging to each output class.\n",
        "        It may be more useful to turn this output back into a crisp class prediction. \n",
        "        We can do this by selecting the class value with the larger probability. \n",
        "        This is also called the arg max function.\n",
        "        '''\n",
        "        outputs = self.forward_propagate(network, activationFunction, row)\n",
        "        return outputs.index(max(outputs))\n",
        "    \n",
        "    def back_propagation(self, train, test, l_rate, n_epoch, n_hidden, activationFunction):\n",
        "        '''\n",
        "        Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "        '''\n",
        "        n_inputs = len(train[0]) - 1\n",
        "        n_outputs = len(set([row[-1] for row in train]))\n",
        "        network = self.initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "        self.train_network(network, activationFunction, train, l_rate, n_epoch, n_outputs)\n",
        "        predictions = list()\n",
        "        for row in test:\n",
        "            prediction = self.predict(network, activationFunction, row)\n",
        "            predictions.append(prediction)\n",
        "        return(predictions)\n",
        "\n",
        "if __name__ == '__main__':    \n",
        "    \n",
        "    seed(1)\n",
        "    mlp = MultilayerNnClassifier()\n",
        "    activationFunction = Tanh()\n",
        "    network = mlp.initialize_network(2, [10,5], 2)\n",
        "    for layer in network:\n",
        "        print(layer)\n",
        "       \n",
        "    # Test forward_propagate\n",
        "    print(\"Test Forward\")\n",
        "    row = [1, 0, None]\n",
        "    output = mlp.forward_propagate(network, activationFunction, row)\n",
        "    print(output)\n",
        "    \n",
        "    # Test backward_propagate_error\n",
        "    print(\"Test backpropagation of error\")\n",
        "    network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
        "            [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
        "    expected = [0, 1]\n",
        "    mlp.backward_propagate_error(network, activationFunction, expected)\n",
        "    for layer in network:\n",
        "        print(layer)\n",
        "      \n",
        "    # Test training backprop algorithm\n",
        "    print(\"Test training backprop algorithm\")\n",
        "    seed(1)\n",
        "    dataset = [[2.7810836, 2.550537003, 0],\n",
        "        [1.465489372, 2.362125076, 0],\n",
        "        [3.396561688, 4.400293529, 0],\n",
        "        [1.38807019, 1.850220317, 0],\n",
        "        [3.06407232, 3.005305973, 0],\n",
        "        [7.627531214, 2.759262235, 1],\n",
        "        [5.332441248, 2.088626775, 1],\n",
        "        [6.922596716, 1.77106367, 1],\n",
        "        [8.675418651, -0.242068655, 1],\n",
        "        [7.673756466, 3.508563011, 1]]\n",
        "    n_inputs = len(dataset[0]) - 1\n",
        "    n_outputs = len(set([row[-1] for row in dataset]))\n",
        "    network = mlp.initialize_network(n_inputs, [2], n_outputs)\n",
        "    mlp.train_network(network, activationFunction, dataset, 0.5, 20, n_outputs)    \n",
        "    for layer in network:\n",
        "        print(layer)\n",
        "    for row in dataset:\n",
        "        prediction = mlp.predict(network, activationFunction, row)\n",
        "        print('Expected=%d, Got=%d' % (row[-1], prediction))  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Batch GRADIENT DESCENT "
      ],
      "metadata": {
        "id": "CV92ZoPLHj50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.datasets.samples_generator import make_regression \n",
        "import pylab\n",
        "from scipy import stats\n",
        "\n",
        "def gradient_descent_2(alpha, x, y, numIterations):\n",
        "    m = x.shape[0] # number of samples\n",
        "    theta = np.ones(2)\n",
        "    x_transpose = x.transpose()\n",
        "    for iter in range(0, numIterations):\n",
        "        hypothesis = np.dot(x, theta)\n",
        "        loss = hypothesis - y\n",
        "        J = np.sum(loss ** 2) / (2 * m)  # cost\n",
        "        print(\"iter %s | J: %.3f\" % (iter, J))  \n",
        "        gradient = np.dot(x_transpose, loss) / m         \n",
        "        theta = theta - alpha * gradient  # update\n",
        "    return theta\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    x, y = make_regression(n_samples=100, n_features=1, n_informative=1, \n",
        "                        random_state=0, noise=35) \n",
        "    m, n = np.shape(x)\n",
        "    x = np.c_[ np.ones(m), x] # insert column\n",
        "    alpha = 0.01 # learning rate\n",
        "    theta = gradient_descent_2(alpha, x, y, 1000)\n",
        "\n",
        "    # plot\n",
        "    for i in range(x.shape[1]):\n",
        "        y_predict = theta[0] + theta[1]*x \n",
        "    pylab.plot(x[:,1],y,'o')\n",
        "    pylab.plot(x,y_predict,'k-')\n",
        "    pylab.show()\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "nxhVgdSzJBDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iter 0 | J: 1604.873\n",
        "\n",
        "iter 1 | J: 1586.636\n",
        "\n",
        "iter 2 | J: 1568.768\n",
        "\n",
        "iter 3 | J: 1551.261\n",
        "...\n",
        "\n",
        "iter 997 | J: 699.300\n",
        "\n",
        "iter 998 | J: 699.300\n",
        "\n",
        "iter 999 | J: 699.300\n",
        "\n",
        "theta = [ -2.84837957  43.20234847]"
      ],
      "metadata": {
        "id": "jDgeNPshJQWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "483AGx1CZvBi"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abGzH61WZw6r",
        "outputId": "243c760d-e8f0-4e39-fbef-017a327dfa9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Height     Weight    Male\n",
            "0  151.765  47.825606      1\n",
            "1  139.700  36.485807      0\n",
            "2  136.525  31.864838      0\n",
            "3  156.845  53.041915      1\n",
            "4  145.415  41.276872      0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(60, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_Data_Normal = pd.read_csv(\"Data_Normal.txt\")\n",
        "print(df_Data_Normal.head())\n",
        "df_Data_Normal.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Glass"
      ],
      "metadata": {
        "id": "Bf6XXjBqni0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('Glass.txt', 'r') as infile, open('Glass.csv', 'w') as outfile:\n",
        "      stripped = (line.strip() for line in infile)\n",
        "      lines = (line.split(\"\\t\") for line in stripped if line)\n",
        "      writer = csv.writer(outfile)\n",
        "      writer.writerows(lines)"
      ],
      "metadata": {
        "id": "ImJTX7RArCYw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Glass = pd.read_csv(\"Glass.csv\")"
      ],
      "metadata": {
        "id": "vOQvIyyInhKV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalize"
      ],
      "metadata": {
        "id": "7dJomxBIr1NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "d_Glass = preprocessing.normalize(df_Glass)\n",
        "scaled_df_Normal_Glass = pd.DataFrame(d_Glass, columns=['1','2','3','4','5','6','7','8','9','10','11','12'])\n",
        "scaled_df_Normal_Glass.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RDX_LA84rzfu",
        "outputId": "8adf1dbd-c0dc-4f35-f5b0-533ddb6ee0c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-951c157c-d423-4f50-b761-5d25308cd0c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.755929</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-951c157c-d423-4f50-b761-5d25308cd0c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-951c157c-d423-4f50-b761-5d25308cd0c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-951c157c-d423-4f50-b761-5d25308cd0c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     1    2    3         4         5  ...         8    9   10   11   12\n",
              "0  0.0  0.5  0.0  0.500000  0.000000  ...  0.500000  0.0  0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  0.500000  0.500000  ...  0.500000  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.5  0.0  0.500000  0.000000  ...  0.500000  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.5  0.0  0.500000  0.000000  ...  0.500000  0.0  0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.377964  0.377964  ...  0.377964  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P0qlZ38LZ434",
        "outputId": "06358864-d59c-42fb-9d7d-0adf0bf04aa5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d37f91b-2ff4-488a-966f-a2b696329cb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.953744</td>\n",
              "      <td>0.300553</td>\n",
              "      <td>0.006284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.967546</td>\n",
              "      <td>0.252696</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.973827</td>\n",
              "      <td>0.227291</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.947280</td>\n",
              "      <td>0.320351</td>\n",
              "      <td>0.006040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.961995</td>\n",
              "      <td>0.273068</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d37f91b-2ff4-488a-966f-a2b696329cb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d37f91b-2ff4-488a-966f-a2b696329cb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d37f91b-2ff4-488a-966f-a2b696329cb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Height    Weight      Male\n",
              "0  0.953744  0.300553  0.006284\n",
              "1  0.967546  0.252696  0.000000\n",
              "2  0.973827  0.227291  0.000000\n",
              "3  0.947280  0.320351  0.006040\n",
              "4  0.961995  0.273068  0.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "d = preprocessing.normalize(df_Data_Normal)\n",
        "scaled_df_Normal = pd.DataFrame(d, columns=['Height','Weight','Male'])\n",
        "scaled_df_Normal.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8eLCzfX4Z9S3"
      },
      "outputs": [],
      "source": [
        "X_Glass = scaled_df_Normal_Glass.loc[:, ['1','2','3','4','5','6','7','8','9','10','11']]\n",
        "y_Glass = scaled_df_Normal_Glass.loc[:, ['12']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = scaled_df_Normal.Height\n",
        "y = scaled_df_Normal.Weight"
      ],
      "metadata": {
        "id": "23No5gkbsYHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYcJ4f48af5b"
      },
      "source": [
        "#Split 30% Test and 70% Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfpcFScxaVPD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_G, X_test_G, y_train_G, y_test_G = train_test_split(X_Glass, y_Glass, test_size=0.30, random_state=42)"
      ],
      "metadata": {
        "id": "R8xnAisvtmPm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o9vPpHXJaDZS"
      },
      "outputs": [],
      "source": [
        "def ssr_gradient(x, y, b):\n",
        "    res = b[0] + b[1] * x - y\n",
        "    return res.mean(), (res * x).mean()  # .mean() is a method of np.ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKnkXpl-ZY29"
      },
      "outputs": [],
      "source": [
        "gradient_descent(\n",
        "ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008,\n",
        "n_iter=100_000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(\n",
        "ssr_gradient, X_Glass, y_Glass, start=[0.5, 0.5], learn_rate=0.0008,\n",
        "n_iter=100_000\n",
        ")"
      ],
      "metadata": {
        "id": "IDK9Eq6HvQJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snYatszaa6Yj"
      },
      "source": [
        "#Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKbRxE4oa78C"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqn85R5TbXCl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlkTW4d8ba3K"
      },
      "outputs": [],
      "source": [
        "target_names = ['class 0', 'class 1', 'class 2']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWIoCXArbeCR"
      },
      "source": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "     class 0       0.67      1.00      0.80         2\n",
        "     class 1       0.00      0.00      0.00         1\n",
        "     class 2       1.00      0.50      0.67         2\n",
        "\n",
        "    accuracy                           0.60         5\n",
        "   macro avg       0.56      0.50      0.49         5\n",
        "weighted avg       0.67      0.60      0.59         5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true_Glass, y_pred_Glass)"
      ],
      "metadata": {
        "id": "qI-wJbrXue8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names_Glass = ['1','2','3','4','5']\n",
        "print(classification_report(y_true_Glass, y_pred_Glass, target_names=target_names_Glass))"
      ],
      "metadata": {
        "id": "AIAWIj4vulUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "     class 0       0.87      1.00      0.80         2\n",
        "     class 1       0.00      0.00      0.00         1\n",
        "     class 2       1.00      0.70      0.84         2\n",
        "\n",
        "    accuracy                           0.87         5\n",
        "   macro avg       0.76      0.50      0.79         5\n",
        "weighted avg       0.77      0.60      0.80         5"
      ],
      "metadata": {
        "id": "LS38GKG0vHWT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Part_B_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}